---
title: "Practical Machine Learning Course Project. Training Movements Analysis."
author: "Vira Yakusha"
date: "Wednesday, July 22, 2015"
output: html_document
---

# Synopsis
This is the Course Project for the Practical Machine Learning by Coursera. The dataset contains of the test data (pml-testing.csv) and training data (pml-training.csv) and generated by the Human Activity Recognition project (http://groupware.les.inf.puc-rio.br/har) 
The test and train data are generated by 4 test subjects, doing 8 hours of dumbell lifting activities. The activities are performed in 5 different ways, only one of which is correct (class A). Other classes represent common excercising mistakes. The goal of this machine learning project is to generate the algorythm which will identify correct or incorrect version of the movement with the high level of accuracy.

### Project requirements:
"The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases".

## 1. Dataset exploratory analysis and preliminary modifications.

```{r}
##Load the data and get some preliminary 
setwd("~/R/MachineLearning")
library(caret)

ptrain <- read.csv("pml-training.csv")
ptest <- read.csv("pml-testing.csv")
dim(ptrain)
dim(ptest)

## summary(ptrain)
```
We can see that the evaluation dataset consists of 20 records (the test cases mentioned in the project requirements), while the training dataset has 19622 records. Both datasets have identical number of fields (variables). Also preliminary view showed some values as "#DIV/0!", which were transformed into "NA" strings for consistency. 
The next steps are designed to modify the training dataset, to make it easier to process for the machine learning algorythm(s).
Too many values in the dataset are "NA", which cannot be helpful for the further analysis. 
```{r}
## Remove columns with near zero variance
nzv <- nearZeroVar(ptrain)
ptrain <- ptrain[, -nzv]
ptest <- ptest[, -nzv]

## Remove columns where NA constitute most of the data
mostlyNA <- sapply(ptrain, function(x) mean(is.na(x))) > 0.95
ptrain <- ptrain[, mostlyNA==F]
ptest <- ptest[, mostlyNA==F]

## Remove first five columns with non-relevant info (subject's names, timestamp etc.)
ptrain <- ptrain[, -(1:5)]
ptest <- ptest[, -(1:5)]

## See the number of columns/variables got dramatically reduced.
dim(ptrain)
dim(ptest)
```
## 2. Model Selection and use of the training set to create initial model.
Once the original test and tran datasets got modified in exactly the same fashion, one can start with dividing the train datasets into two sub-sets - one for creating the model, and another - for fitting one.

Since, even after the reduction of columns/variables, number of variables is still very high, Random Forests algorythm seems to be like a good first try in the search for an adequate model.
```{r}


## Divide the original training set into two sub-sets
set.seed(10)
inTrain <- createDataPartition(y=ptrain$classe, p=0.7, list=F)
trainSetBig <- ptrain[inTrain, ]
trainSetSmall <- ptrain[-inTrain, ]

## Create set of train controls using method "CV" with three-fold parameter
fitControl <- trainControl(method="cv", number=3, verboseIter=F)
## use this train controls set on the training subset
fit <- train(classe ~ ., data=trainSetBig, method="rf", trControl=fitControl)
fit$finalModel
```
As we can see, the results of this model are highly accurate - with the accuracy rate = 0.988. This result can be readily applied to solve the real-time problem, so other models can be tried, but it is not really necessary. 


```{r}
## Fit the result model from above to the 'test' subset from the original test dataset
trainResult <- predict(fit, newdata=trainSetSmall)
## See the results
confusionMatrix(trainSetSmall$classe, trainResult)
```
As we can see, the results are very good: 

## 3. Application of the model to the testing set and generation of output files.
```{r}
## Predict on the test set
trainResult <- predict(fit, newdata=ptest)
## Convert the test set into the array of characters
trainResult <- as.character(trainResult)

## Use "Coursera provided" code for the function that would write each element of predictions array into the text file
 pml_write_files <- function(x) {
   n <- length(x)
   for(i in 1:n) {
      filename <- paste0("problem_id_", i, ".txt")
      write.table(x[i], file=filename, quote=F, row.names=F, col.names=F)
    } 
}
## Use the function to write an array.
pml_write_files(trainResult)
```